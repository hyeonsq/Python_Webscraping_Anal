{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ac9f5f9",
   "metadata": {},
   "source": [
    "### 2-3. 하나의 네이버 웹툰과 여러개의 회차에 대한 Image 다운로드 하기(수정중)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04da4790",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "\n",
    "def download_all_episode(title, episode_url):\n",
    "    \n",
    "    req_header = {\n",
    "        'user-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/144.0.0.0 Safari/537.36'\n",
    "    }\n",
    "    \n",
    "    res = requests.get(url, headers=req_header)\n",
    "    \n",
    "    if res.ok:\n",
    "        soup = BeautifulSoup(res.text, 'html.parser')\n",
    "        # 뉴스 기사 div 태그 선택 (각 뉴스 기사 단위)\n",
    "        articles = soup.select('div.mduSubjectList div.mlt01')\n",
    "\n",
    "        for article in articles[:5]:\n",
    "            # img 엘리먼트 존재 여부 체크\n",
    "            img_tag = article.select_one('img')\n",
    "            if img_tag and img_tag.get('src'):\n",
    "                img_url = urljoin(url, img_tag['src'])\n",
    "                display(Image(url=img_url))  # 이미지 출력\n",
    "            else:\n",
    "                print('이미지 없음')\n",
    "\n",
    "            # 기사 제목 + 기사 링크\n",
    "            a_tag = article.select_one('a')\n",
    "            title_tag = a_tag.select_one('h2')\n",
    "            title = title_tag.text.strip()\n",
    "            link = urljoin(url, a_tag['href'])\n",
    "            print('기사제목:', title)\n",
    "            print('기사링크:', link)\n",
    "\n",
    "    else:\n",
    "        # 응답(response)이 Error 이면 status code 출력  \n",
    "        print(f'Error Code = {res.status_code}')\n",
    "\n",
    "def download_one_episode(title, no, url):\n",
    "    # 기본 설정\n",
    "    req_header = {'referer': url}\n",
    "    imgdir_name = f'img/{title}/{no}'\n",
    "\n",
    "    # 이미지 저장 폴더가 없으면 생성\n",
    "    os.makedirs(imgdir_name, exist_ok=True)\n",
    "\n",
    "    # 웹 페이지 요청 및 확인\n",
    "    res = requests.get(url)\n",
    "    if not res.ok:\n",
    "        print(f'Error Code = {res.status_code}')\n",
    "        exit()\n",
    "\n",
    "    # 이미지 URL 추출\n",
    "    soup = BeautifulSoup(res.text, 'html.parser')\n",
    "    img_url_list = [img_tag['src'] for img_tag in soup.select(\"img[src*='IMAG01']\")]\n",
    "\n",
    "    # 이미지 다운로드\n",
    "    for img_url in img_url_list:\n",
    "        res = requests.get(img_url, headers=req_header)\n",
    "        if res.ok:\n",
    "            img_data = res.content\n",
    "            file_path = os.path.join(imgdir_name, os.path.basename(img_url))\n",
    "            with open(file_path, 'wb') as file:\n",
    "                print(f'Writing to {file_path} ({len(img_data):,} bytes)')\n",
    "                file.write(img_data)\n",
    "        else:\n",
    "            print(f'Error Code = {res.status_code} for {img_url}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
